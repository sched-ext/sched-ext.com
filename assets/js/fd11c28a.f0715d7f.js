"use strict";(self.webpackChunksched_ext=self.webpackChunksched_ext||[]).push([[781],{1889:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"scheds/rust/scx_layered/README","title":"scx_layered","description":"This is a single user-defined scheduler used within schedext, which is a Linux kernel feature which enables implementing kernel thread schedulers in BPF and dynamically loading them. Read more about schedext.","source":"@site/docs/scheds/rust/scx_layered/README.md","sourceDirName":"scheds/rust/scx_layered","slug":"/scheds/rust/scx_layered/","permalink":"/docs/scheds/rust/scx_layered/","draft":false,"unlisted":false,"editUrl":"https://github.com/sched-ext/scx/blob/main/scheds/rust/scx_layered/README.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"scx_lavd","permalink":"/docs/scheds/rust/scx_lavd/"},"next":{"title":"scx_mitosis","permalink":"/docs/scheds/rust/scx_mitosis/"}}');var i=n(4848),r=n(8453);const a={},l="scx_layered",o={},c=[{value:"Overview",id:"overview",level:2},{value:"How To Install",id:"how-to-install",level:2},{value:"Typical Use Case",id:"typical-use-case",level:2},{value:"Production Ready?",id:"production-ready",level:2},{value:"Tuning scx_layered",id:"tuning-scx_layered",level:2}];function d(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"scx_layered",children:"scx_layered"})}),"\n",(0,i.jsxs)(s.p,{children:["This is a single user-defined scheduler used within ",(0,i.jsx)(s.a,{href:"https://github.com/sched-ext/scx/tree/main",children:"sched_ext"}),", which is a Linux kernel feature which enables implementing kernel thread schedulers in BPF and dynamically loading them. ",(0,i.jsx)(s.a,{href:"https://github.com/sched-ext/scx/tree/main",children:"Read more about sched_ext"}),"."]}),"\n",(0,i.jsx)(s.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(s.p,{children:"A highly configurable multi-layer BPF / user space hybrid scheduler."}),"\n",(0,i.jsxs)(s.p,{children:["scx_layered allows the user to classify tasks into multiple layers, and apply\ndifferent scheduling policies to those layers. For example, a layer could be\ncreated of all tasks that are part of the ",(0,i.jsx)(s.code,{children:"user.slice"})," cgroup slice, and a\npolicy could be specified that ensures that the layer is given at least 80% CPU\nutilization for some subset of CPUs on the system."]}),"\n",(0,i.jsx)(s.h2,{id:"how-to-install",children:"How To Install"}),"\n",(0,i.jsxs)(s.p,{children:["Available as a ",(0,i.jsx)(s.a,{href:"https://crates.io/crates/scx_layered",children:"Rust crate"}),": ",(0,i.jsx)(s.code,{children:"cargo add scx_layered"})]}),"\n",(0,i.jsx)(s.h2,{id:"typical-use-case",children:"Typical Use Case"}),"\n",(0,i.jsx)(s.p,{children:"scx_layered is designed to be highly customizable, and can be targeted for\nspecific applications. For example, if you had a high-priority service that\nrequired priority access to all but 1 physical core to ensure acceptable p99\nlatencies, you could specify that the service would get priority access to all\nbut 1 core on the system. If that service ends up not utilizing all of those\ncores, they could be used by other layers until they're needed."}),"\n",(0,i.jsx)(s.h2,{id:"production-ready",children:"Production Ready?"}),"\n",(0,i.jsx)(s.p,{children:"Yes. If tuned correctly, scx_layered should be performant across various CPU\narchitectures and workloads."}),"\n",(0,i.jsx)(s.p,{children:"That said, you may run into an issue with infeasible weights, where a task with\na very high weight may cause the scheduler to incorrectly leave cores idle\nbecause it thinks they're necessary to accommodate the compute for a single\ntask. This can also happen in CFS, and should soon be addressed for\nscx_layered."}),"\n",(0,i.jsx)(s.h2,{id:"tuning-scx_layered",children:"Tuning scx_layered"}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.code,{children:"scx_layered"})," is designed with specific use cases in mind and may not perform\nas well as a general purpose scheduler for all workloads. It does have topology\nawareness, which can be disabled with the ",(0,i.jsx)(s.code,{children:"-t"})," flag. This may impact\nperformance on NUMA machines, as layers will be able to span NUMA nodes by\ndefault. For configuring ",(0,i.jsx)(s.code,{children:"scx_layered"})," to span across multiple NUMA nodes simply\nsetting all nodes in the ",(0,i.jsx)(s.code,{children:"nodes"})," field of the config."]}),"\n",(0,i.jsxs)(s.p,{children:["For controlling the performance level of different levels (i.e. CPU frequency)\nthe ",(0,i.jsx)(s.code,{children:"perf"})," field can be set. This must be used in combination with the\n",(0,i.jsx)(s.code,{children:"schedutil"})," frequency governor. The value should be from 0-1024 with 1024 being\nmaximum performance. Depending on the system hardware it will translate to\nfrequency, which can also trigger turbo boosting if the value is high enough\nand turbo is enabled."]}),"\n",(0,i.jsxs)(s.p,{children:["Layer affinities can be defined using the ",(0,i.jsx)(s.code,{children:"nodes"})," or ",(0,i.jsx)(s.code,{children:"llcs"})," layer configs. This\nallows for restricting a layer to a NUMA node or LLC. Layers will by default\nattempt to grow within the same NUMA node, however this may change to suppport\ndifferent layer growth strategies in the future. When tuning the ",(0,i.jsx)(s.code,{children:"util_range"}),"\nfor a layer there should be some consideration for how the layer should grow.\nFor example, if the ",(0,i.jsx)(s.code,{children:"util_range"})," lower bound is too high, it may lead to the\nlayer shrinking excessively. This could be ideal for core compaction strategies\nfor a layer, but may poorly utilize hardware, especially in low system\nutilization. The upper bound of the ",(0,i.jsx)(s.code,{children:"util_range"})," controls how the layer grows,\nif set too aggressively the layer could grow fast and prevent other layers from\nutilizing CPUs. Lastly, the ",(0,i.jsx)(s.code,{children:"slice_us"})," can be used to tune the timeslice\nper layer. This is useful if a layer has more latency sensitive tasks, where\ntimeslices should be shorter. Conversely if a layer is largely CPU bound with\nless concerns of latency it may be useful to increase the ",(0,i.jsx)(s.code,{children:"slice_us"})," parameter."]}),"\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.code,{children:"scx_layered"})," can provide performance wins, for certain workloads when\nsufficient tuning on the layer config."]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>l});var t=n(6540);const i={},r=t.createContext(i);function a(e){const s=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:s},e.children)}}}]);